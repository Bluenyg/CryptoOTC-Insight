# src/core/collectors.py
import asyncio
import httpx
import time
import traceback
from typing import Set, List, Dict, Any
from datetime import datetime, timezone, timedelta

# å¯¼å…¥å¯ä»¥ç›´æ¥è°ƒç”¨çš„ç»„ä»¶
from src.agents.small_agents.pipeline import small_agent_graph
from src.schemas.data_models import RawDataInput

# --- é…ç½® ---
FETCH_API_URL = "http://api.ibyteai.com:15008/10Ai/dataCenter/crypto/fetchCryptoPanic"
UPDATE_API_URL = "http://api.ibyteai.com:15008/10Ai/dataCenter/crypto/updatePanicNews"
HEADERS = {'Content-Type': 'application/json'}

# å…¨å±€å»é‡é›†åˆ (åªè¦ç¨‹åºä¸é‡å¯ï¼Œè¿™ä¸ª set ä¸€ç›´æœ‰æ•ˆ)
seen_object_ids: Set[str] = set()


async def mark_as_failed(obj_id: str, reason: str):
    """
    [æ–°å¢] è¾…åŠ©å‡½æ•°ï¼šå½“å¤„ç†å‡ºé”™æ—¶ï¼Œå°†æ–°é—»æ ‡è®°ä¸º Noise (Tag 4)ï¼Œ
    é˜²æ­¢ç¨‹åºä¸‹æ¬¡é‡å¯æ—¶å¡åœ¨åŒä¸€ä¸ªé”™è¯¯çš„ ID ä¸Šã€‚
    """
    payload = {
        "objectId": obj_id,
        "newsTag": 4,  # 4 = å¤„ç†å¤±è´¥/å™ªéŸ³
        "summary": "Processing Failed",
        "analysis": f"System Error: {reason[:100]}"
    }
    try:
        async with httpx.AsyncClient() as client:
            await client.post(UPDATE_API_URL, json=payload, headers=HEADERS, timeout=5.0)
            print(f"ğŸš« [ErrorHandler] å·²å°† ID {obj_id} æ ‡è®°ä¸º Tag 4 (Failed).")
    except Exception as e:
        print(f"âŒ [ErrorHandler] æ ‡è®°å¤±è´¥ ID {obj_id}: {e}")


async def fetch_crypto_news_from_api(client: httpx.AsyncClient, coin_type: int) -> List[Dict[str, Any]]:
    """
    è°ƒç”¨ fetchCryptoPanic æ¥å£è·å–æ–°é—» (ä¿ç•™åŸæœ‰é€»è¾‘)
    """
    end_time = datetime.utcnow()
    # æ—¢ç„¶æ¯20åˆ†é’Ÿè·‘ä¸€æ¬¡ï¼ŒæŸ¥è¿‡å» 12å°æ—¶ è¶³å¤Ÿäº†ï¼Œä¸ç”¨æŸ¥24å°æ—¶ï¼Œå‡å°‘æ•°æ®é‡
    start_time = end_time - timedelta(hours=12)

    start_str = start_time.strftime("%Y-%m-%dT%H:%M:%S")
    end_str = end_time.strftime("%Y-%m-%dT%H:%M:%S")

    json_data = {
        "type": coin_type,
        "startTime": start_str,
        "endTime": end_str
    }

    try:
        response = await client.post(FETCH_API_URL, headers=HEADERS, json=json_data, timeout=15.0)
        if response.status_code != 200:
            print(f"âš ï¸ [NewsCollector] API è¯·æ±‚å¤±è´¥ (Type {coin_type}) Code: {response.status_code}")
            return []
        return response.json()
    except Exception as e:
        print(f"âŒ [NewsCollector] è¯·æ±‚å¼‚å¸¸ (Type {coin_type}): {e}")
        return []


def parse_api_timestamp(time_str: str) -> float:
    if not time_str: return time.time()
    try:
        clean_str = time_str.replace("Z", "").strip()
        if "T" in clean_str:
            dt = datetime.strptime(clean_str, "%Y-%m-%dT%H:%M:%S")
        else:
            dt = datetime.strptime(clean_str, "%Y-%m-%d %H:%M:%S")
        dt = dt.replace(tzinfo=timezone.utc)
        return dt.timestamp()
    except Exception:
        return time.time()


# ==========================================
# âš¡ æ ¸å¿ƒä¿®æ”¹ï¼šå»é™¤ While True å¾ªç¯
# ==========================================
async def run_news_collector():
    """
    æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„é‡‡é›†æ¸…æ´—æµç¨‹ï¼Œç„¶åç«‹å³è¿”å›ã€‚
    ç”± main.py çš„ master_scheduler å®šæ—¶è°ƒç”¨ã€‚
    """
    print(f"ğŸ“¥ [Collector] å¼€å§‹æ–°ä¸€è½®é‡‡é›†ä»»åŠ¡...")

    # è®°å½•æœ¬è½®å¤„ç†æ•°é‡
    processed_count = 0
    loop_start = time.time()

    try:
        async with httpx.AsyncClient() as client:
            # 1. æ‹‰å–æ•°æ®
            btc_news = await fetch_crypto_news_from_api(client, 1)
            eth_news = await fetch_crypto_news_from_api(client, 2)

            all_news_items = []
            if isinstance(btc_news, list): all_news_items.extend(btc_news)
            if isinstance(eth_news, list): all_news_items.extend(eth_news)

            if not all_news_items:
                print("ğŸ’“ [Collector] æœ¬è½®æœªè·å–åˆ°åŸå§‹æ•°æ®ã€‚")
                return  # ç›´æ¥ç»“æŸ

            # 2. æ’åº
            all_news_items.sort(
                key=lambda x: parse_api_timestamp(x.get('time')),
                reverse=True
            )

            # 3. éå†å¤„ç†
            for item in all_news_items:
                obj_id = item.get('objectId')
                current_tag = item.get('newsTag')

                # A. è¿‡æ»¤å·²å¤„ç†çš„
                if current_tag is not None and current_tag != 0:
                    continue

                # B. å†…å­˜å»é‡ (ä¾èµ–å…¨å±€å˜é‡ seen_object_ids)
                if obj_id in seen_object_ids:
                    continue

                if obj_id:
                    seen_object_ids.add(obj_id)
                    processed_count += 1

                    # --- å‡†å¤‡ Pipeline ---
                    title = item.get('title') or "No Title"
                    target_url = item.get('link') or ""

                    print(f"âš™ï¸ [Pipeline] Processing ID: {obj_id} | {title[:30]}...")

                    raw_data = RawDataInput(
                        source=target_url,
                        timestamp=parse_api_timestamp(item.get('time')),
                        content=f"Title: {title}\nDescription: {item.get('description') or ''}",
                        object_id=obj_id
                    )

                    try:
                        # è°ƒç”¨ LangGraph è¿›è¡Œæ¸…æ´—
                        # è¿™é‡Œä¾ç„¶æ˜¯ awaitï¼Œä¿è¯å¿…é¡»æ¸…æ´—å®Œè¿™ä¸€æ¡ï¼Œæ‰ç®—å®Œæˆ
                        await small_agent_graph.ainvoke({"raw_data": raw_data})

                        # çŸ­æš‚åœé¡¿ï¼Œé˜²æ­¢å¹¶å‘è¿‡é«˜
                        await asyncio.sleep(0.2)

                    except Exception as agent_e:
                        print(f"âŒ [Pipeline Error] ID: {obj_id}")
                        traceback.print_exc()
                        # å‡ºé”™æ ‡è®°ï¼Œé˜²æ­¢ä¸‹æ¬¡å¡ä½
                        await mark_as_failed(obj_id, str(agent_e))

    except Exception as e:
        print(f"ğŸ”¥ [Collector Critical] æœ¬è½®é‡‡é›†å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        traceback.print_exc()

    duration = time.time() - loop_start
    print(f"âœ… [Collector] æœ¬è½®ç»“æŸã€‚æ–°å¢å¤„ç†: {processed_count} æ¡ã€‚è€—æ—¶: {duration:.2f}s")
    # å‡½æ•°è‡ªç„¶ç»“æŸï¼Œè¿”å›æ§åˆ¶æƒç»™ Master Scheduler